<div class="flex justify-center">
  <article class="my-2 prose w-full text-white">
    <h1 class="text-white">Chains of Thought and Action (CoTA)</h1>
    <p>
      We define a <i>chain of thought and action</i> as a series of reasoning
      steps and visible tool use whereby agentic AI systems show both the
      intermediate reasoning and the inputs and outputs of actions taken.
    </p>

    <h2 class="text-white">Chain of Thought</h2>
    <p>
      A 'chain of thought' is a series of intermediate reasoning steps that
      significantly improves the ability of large language models to perform
      complex reasoning. Introduced in
      <a
        href="https://arxiv.org/abs/2201.11903"
        class="text-white hover:opacity-75 underline"
        target="_blank"
        >Chain-of-Thought Prompting Elicits Reasoning in Large Language
        Models</a
      >, this technique demonstrated a 20-30% improvement in reasoning accuracy by having models explain their solutions step-by-step, rather than jumping directly to answers.
    </p>

    <p>
      OpenAI has embraced this concept with their O1 series of models, which are
      specifically designed to "spend more time thinking before they respond."
      However, OpenAI has been
      <a
        href="https://x.com/parshantdeep/status/1834281496850694544"
        class="text-white hover:opacity-75 underline"
        target="_blank"
        >criticized</a
      >
      for not showing the chain of thought to users, unlike competitors like
      DeepSeek which display the complete, unedited reasoning steps.
    </p>

    <h2 class="text-white">And Action</h2>
    <p>
      While chain of thought reveals an AI's reasoning process, we need to
      extend this transparency to actions as well. This section will demonstrate
      how we can make AI systems show not just their thinking, but also their
      tool use and actions in achieving tasks.
    </p>

    <h2 class="text-white">An Example</h2>
    <p>
      This month we'll release our first "problem solver" product, an agent that turns a GitHub issue into a pull request through a combination of reasoning and tool use. The agent traverses codebases and documentation, uses CI tools and tests, and importantly, shows the full trace of both its reasoning (using DeepSeek R1) and tool use (displaying input/output of each tool as sent to the LLM).
    </p>

    <p>
      The workflow combines multiple models and tools:
    </p>

    <ul class="list-disc list-inside text-white">
      <li>Build repository map from issue context (automated script)</li>
      <li>Identify relevant files (DeepSeek R1 for reasoning, Mistral Small for structured output)</li>
      <li>Traverse and analyze codebase (file readers, AST parsers)</li>
      <li>Plan changes (DeepSeek R1 with full reasoning trace)</li>
      <li>Generate and test code changes (coding tools, CI integration)</li>
      <li>Create pull request with detailed explanation (GitHub API tools)</li>
    </ul>

    <p>
      At each step, both the reasoning process and tool interactions are logged and displayed, creating a complete audit trail of how the solution was developed.
    </p>
  </article>
</div>